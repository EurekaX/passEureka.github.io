<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>仿生人会涮电子羊吗</title>
  
  <subtitle>Then he will be a true love of mine</subtitle>
  <link href="https://eurekax.github.io/atom.xml" rel="self"/>
  
  <link href="https://eurekax.github.io/"/>
  <updated>2021-03-24T08:00:15.495Z</updated>
  <id>https://eurekax.github.io/</id>
  
  <author>
    <name>Wendy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>synchronized锁之间的对比</title>
    <link href="https://eurekax.github.io/2021/03/23/Java%E5%B9%B6%E5%8F%91-%E9%94%81/"/>
    <id>https://eurekax.github.io/2021/03/23/Java%E5%B9%B6%E5%8F%91-%E9%94%81/</id>
    <published>2021-03-23T09:18:50.834Z</published>
    <updated>2021-03-24T08:00:15.495Z</updated>
    
    <content type="html"><![CDATA[<h1 id="synchronized锁之间的对比"><a href="#synchronized锁之间的对比" class="headerlink" title="synchronized锁之间的对比"></a>synchronized锁之间的对比</h1><p>javaSE1.6为了减少获得<u>锁和释放锁所带来的性能消耗</u>，引入了偏向锁和轻量级锁的概念。锁的状态级别依次从低到高是：无锁、偏向锁、轻量级锁、重量级锁状态。锁只能升级无法降级。</p><h2 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h2><p>当一个线程访问同步块并获取锁时，会在对象头和帧栈的锁记录中存储锁偏向的进程ID，以后该线程在进入和退出同步块时就不需要进行CAS操作（compare and swap)来加锁和解锁，只需简单的测试一下对象头中断Mark Word里是否存储着指向当前线程的偏向锁。</p><p>偏向锁采用等到竞争出现才释放锁的机制。当其他线程尝试竞争偏向锁的时候，持有偏向锁的线程才会释放。</p><p>当线程访问同步代码块。首先查看当前锁状态是否是偏向锁(可偏向状态) 1、如果是偏向锁： 1.1、检查当前mark word中记录是否是当前线程id，如果是当前线程id，则获得偏向锁执行同步代码块。 1.2、，如果不是当前线程id，cas操作替换线程id，替换成功获得偏向锁(线程复用)，替换失败锁撤销升级轻量锁(同一类对象多次撤销升级达到阈值20，则批量重偏向)</p><h2 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h2><h2 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;synchronized锁之间的对比&quot;&gt;&lt;a href=&quot;#synchronized锁之间的对比&quot; class=&quot;headerlink&quot; title=&quot;synchronized锁之间的对比&quot;&gt;&lt;/a&gt;synchronized锁之间的对比&lt;/h1&gt;&lt;p&gt;javaSE</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Java对象头</title>
    <link href="https://eurekax.github.io/2021/03/23/Java%E5%AF%B9%E8%B1%A1%E5%A4%B4/"/>
    <id>https://eurekax.github.io/2021/03/23/Java%E5%AF%B9%E8%B1%A1%E5%A4%B4/</id>
    <published>2021-03-23T09:18:50.830Z</published>
    <updated>2021-03-24T07:25:46.132Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java对象头"><a href="#Java对象头" class="headerlink" title="Java对象头"></a>Java对象头</h1><p>Java对象保存在内存中时，由以下三部分组成：1对象头2实例数据3对齐填充字节</p><h2 id="java对象头"><a href="#java对象头" class="headerlink" title="java对象头"></a>java对象头</h2><p>由以下内容组成</p><table><thead><tr><th align="center">长度</th><th align="center">内容</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">32/64bit</td><td align="center">mark word</td><td align="center">存储hash code或锁信息</td></tr><tr><td align="center">32/64bit</td><td align="center">Class Metadata Address</td><td align="center">对象类型数据的指针</td></tr><tr><td align="center">32/64bit</td><td align="center">Array length</td><td align="center">数组的长度（当前对象为数组）</td></tr></tbody></table><p>在运行期间，Mark Word中存储的数据会随着锁标志位的变化而变化。</p><table>    <tr>        <td rowspan="2">锁状态</td>         <td colspan="2">25bit</td>         <td rowspan="2">4bit</td>         <td>1bit</td>         <td>2bit</td>         </tr>    <tr>        <td>23bit</td>        <td>2bit</td>        <td>是否是偏向锁</td>        <td>锁标志位</td>        </tr>    <tr>        <td>轻量级锁</td>        <td colspan="4">指向栈中锁记录的指针</td>         <td>00</td>    </tr>    <tr>        <td >重量级锁</td>            <td colspan="4">指向互斥量（重量级锁）的指针</td>         <td>10</td>    </tr>    <tr>        <td>GC标记</td>        <td colspan="4">空</td>         <td>11</td>    </tr>    <tr>    <td>偏向锁</td>    <td>线程ID</td>    <td>Epoch</td>    <td>对象分代年龄</td>    <td>1</td>    <td>01</td>    </tr><table>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Java对象头&quot;&gt;&lt;a href=&quot;#Java对象头&quot; class=&quot;headerlink&quot; title=&quot;Java对象头&quot;&gt;&lt;/a&gt;Java对象头&lt;/h1&gt;&lt;p&gt;Java对象保存在内存中时，由以下三部分组成：1对象头2实例数据3对齐填充字节&lt;/p&gt;
&lt;h2 id</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>机器学习线性代数基础</title>
    <link href="https://eurekax.github.io/2020/11/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    <id>https://eurekax.github.io/2020/11/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</id>
    <published>2020-11-05T04:36:09.000Z</published>
    <updated>2021-03-24T08:00:12.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机器学习线性代数基础"><a href="#机器学习线性代数基础" class="headerlink" title="机器学习线性代数基础"></a>机器学习线性代数基础</h1><p>在机器学习和深度学习中，我们涉及到线性代数的这些知识：</p><ul><li><p>向量与矩阵</p></li><li><p>线性方程组</p></li><li><p>向量空间</p></li><li><p>偏差</p></li></ul><p>通过线性代数，我们可以实现以下机器学习或深度学习方法：</p><ul><li><p>推导回归方程</p></li><li><p>通过线性方程预测目标值</p></li><li><p>支持向量机SVM</p></li><li><p>降维</p></li><li><p>均方差或损失函数</p></li><li><p>正则化</p></li><li><p>协方差矩阵</p></li><li><p>卷积</p><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>矩阵是线性代数的重要概念。一个m<em>n矩阵包含mn个元素，可用于线性方程组或线性映射的计算，也可将其视为一个由m</em>n个实值元素组成的元组。</p></li></ul><p><img src="/images/pasted-1.png" alt="upload successful"></p><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><p>在线性代数中，向量是大小为n*1的矩阵，即只有一列。</p><h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><p>矩阵乘法是行和列的点积，其中一个矩阵的行与另一个矩阵列相乘并求和。</p><p><img src="/images/pasted-2.png" alt="upload successful"></p><h3 id="矩阵乘法在线性回归上的运用"><a href="#矩阵乘法在线性回归上的运用" class="headerlink" title="矩阵乘法在线性回归上的运用"></a>矩阵乘法在线性回归上的运用</h3><p>通过多种特征可以预测房屋价格。下表展示了不同房屋的特征及其价格。</p><p><img src="/images/pasted-3.png" alt="不同房屋的特征及其价格"><br>        不同房屋的特征及其价格</p><p><img src="/images/pasted-4.png" alt="upload successful"><br>令：</p><p><img src="/images/pasted-5.png" alt="upload successful"> 特征及其系数<br>可得到房价预测函数</p><p><img src="/images/pasted-6.png" alt="upload successful"></p><h2 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h2><p>对于矩阵A∈R^m<em>n，有矩阵B∈R^n</em>m满足b_ij = a_ij，称为A的转置，即B=A^T。</p><p><img src="/images/pasted-7.png" alt="upload successful"><br>numpy函数：<code> np.transpose(matrix)</code></p><h2 id="逆矩阵"><a href="#逆矩阵" class="headerlink" title="逆矩阵"></a>逆矩阵</h2><p>对n阶矩阵A，有矩阵B∈R^n*n满足AB =I_n（单位矩阵）= BA的性质，称B为A的逆，表示为A^-1。</p><p><code>np.linalg.inv(matrix)</code></p><p>求矩阵 A 的伪逆（广义逆矩阵）:</p><p><code>np.linalg.pinv(matrix) </code></p><h2 id="正交矩阵"><a href="#正交矩阵" class="headerlink" title="正交矩阵"></a>正交矩阵</h2><p>当且仅当矩阵列向量组是单位正交向量组时，n阶矩阵A∈R^n*n是正交矩阵，有：</p><p><img src="/images/pasted-8.png" alt="upload successful"></p><h2 id="对角矩阵"><a href="#对角矩阵" class="headerlink" title="对角矩阵"></a>对角矩阵</h2><p>在n阶矩阵A∈R^n*n中，除主对角线上的元素，其他所有元素均为零，称其为对角矩阵。</p><h3 id="正规方程的转置矩阵和逆矩阵"><a href="#正规方程的转置矩阵和逆矩阵" class="headerlink" title="正规方程的转置矩阵和逆矩阵"></a>正规方程的转置矩阵和逆矩阵</h3><p><img src="/images/pasted-13.png" alt="upload successful"><br>正规方程通过计算theta j的导数，将其设为零来最小化J。无需Gradient Descent就可直接得到θ的值，θ见下图。</p><p><img src="/images/pasted-10.png" alt="upload successful"></p><p><img src="/images/pasted-11.png" alt="upload successful"><br>创建特征x和目标y的矩阵：<br>import numpy as np Features<br>x = np.array([[2, 1834, 1],[3, 1534, 2],[2, 962, 3]])# Target or Pricey = [8500, 9600, 258800]</p><p>计算x的转置：<br><img src="/images/pasted-12.png" alt="upload successful"><br>计算转置矩阵与原始矩阵乘积的逆：</p><h3 id="线性回归中的线性方程"><a href="#线性回归中的线性方程" class="headerlink" title="线性回归中的线性方程"></a>线性回归中的线性方程</h3><p>回归就是给出线性方程的过程，该过程试图找到满足特定数据集的最优曲线<br>通过线性回归预测平方英尺和房屋价格的关系。<br>数据读取：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df &#x3D; pd.read_csv(&#39;house_price.csv&#39;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></div><p>计算均值、方差、协方差：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def get_mean(value):</span><br><span class="line">    total &#x3D; sum(value)</span><br><span class="line">    length &#x3D; len(value)</span><br><span class="line">    mean &#x3D; total&#x2F;length</span><br><span class="line">    return mean</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><figcaption><span>get_variance(value):</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mean &#x3D; get_mean(value)</span><br><span class="line">mean_difference_square &#x3D; [pow((item - mean), 2) for item in value]</span><br><span class="line">variance &#x3D; sum(mean_difference_square)&#x2F;float(len(value)-1)</span><br><span class="line">return variance&#96;</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><figcaption><span>get_covariance(value1, value2):</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">value1_mean &#x3D; get_mean(value1)</span><br><span class="line">value2_mean &#x3D; get_mean(value2)</span><br><span class="line">values_size &#x3D; len(value1)</span><br><span class="line">covariance &#x3D; 0.0    for i in range(0, values_size):</span><br><span class="line">    covariance +&#x3D; (value1[i] - value1_mean) * (value2[i] - value2_mean)</span><br><span class="line">return covariance &#x2F; float(values_size - 1)&#96;</span><br></pre></td></tr></table></figure></div><pre><code><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> 线性回归过程:</span><br><span class="line">​&#96;&#96;&#96; </span><br><span class="line">def linear_regression(df):</span><br><span class="line">   X &#x3D; df[&#39;square_feet&#39;]</span><br><span class="line">   Y &#x3D; df[&#39;price&#39;]</span><br><span class="line">   m &#x3D; len(X)</span><br><span class="line">   square_feet_mean &#x3D; get_mean(X)</span><br><span class="line">   price_mean &#x3D; get_mean(Y)</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#96;&#96;&#96;  #variance of X</span><br><span class="line">  square_feet_variance &#x3D; get_variance(X)</span><br><span class="line">  price_variance &#x3D; get_variance(Y)</span><br></pre></td></tr></table></figure></div></code></pre><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">covariance_of_price_and_square_feet &#x3D; get_covariance(X, Y)</span><br><span class="line">  w1 &#x3D; covariance_of_price_and_square_feet &#x2F; float(square_feet_variance)</span><br><span class="line">  w0 &#x3D; price_mean - w1 * square_feet_mean</span><br><span class="line"></span><br><span class="line">  #prediction --&gt; Linear Equation</span><br><span class="line">  prediction &#x3D; w0 + w1 * X</span><br><span class="line"></span><br><span class="line">  df[&#39;price (prediction)&#39;] &#x3D; prediction</span><br><span class="line">  return df[&#39;price (prediction)&#39;] </span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="Code"><figure class="iseeu highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></div><h2 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h2><p>向量范数可用于衡量向量的大小，也就是说，范数|| x ||表示变量x的大小，范数|| x-y ||表示两个向量x和y之间的距离。</p><p>向量范数计算公式：</p><p><img src="/images/pasted-14.png" alt="upload successful"><br>常用的向量范数为一阶和二阶：</p><p>一阶范数也叫Manhattan范数</p><p>二阶范数也叫Euclidean范数 </p><p>在正则化中会用到一阶和二阶范数。<br>一阶范数/Manhattan范数<br>x∈R^n的L1范数定义为：</p><p><img src="/images/pasted-15.png" alt="upload successful"></p><p>示意图：<br><img src="/images/pasted-16.png" alt="upload successful"></p><p>L2范数/Euclidean范数<br>x∈R^n的L2范数定义为：</p><p><img src="/images/pasted-17.png" alt="upload successful"></p><p><img src="/images/pasted-18.png" alt="upload successful"></p><h2 id="机器学习中的正则化"><a href="#机器学习中的正则化" class="headerlink" title="机器学习中的正则化"></a>机器学习中的正则化</h2><p>正则化是指通过修改损失函数以惩罚学习权重的过程，是避免过拟合的有效方式。</p><p>正则化在机器学习中的作用：</p><ul><li><p>解决共线性问题</p></li><li><p>除去噪声数据</p></li><li><p>避免过拟合</p></li><li><p>提升模型表现</p></li></ul><p>标准正则化技术包括：</p><ul><li><p>L1正则化（Lasso）</p></li><li><p>L2正则化（Ridge）</p></li></ul><h2 id="L1正则化（Lasso）"><a href="#L1正则化（Lasso）" class="headerlink" title="L1正则化（Lasso）"></a>L1正则化（Lasso）</h2><p><img src="/images/pasted-19.png" alt="upload successful"></p><h2 id="L2正则化（Ridge）"><a href="#L2正则化（Ridge）" class="headerlink" title="L2正则化（Ridge）"></a>L2正则化（Ridge）</h2><p>Ridge正则化表达式：</p><p><img src="/images/pasted-20.png" alt="upload successful"></p><h2 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h2><p>方差：</p><p><img src="/images/pasted-21.png" alt="upload successful"></p><p><img src="/images/pasted-22.png" alt="upload successful"><br>方差的限制在于无法表示变量直接的关系<br>协方差可用于衡量两个变量之间的关系；</p><p><img src="/images/pasted-23.png" alt="upload successful"></p><p>协方差矩阵是方阵，其中每个元素表示两个随机矢量之间的协方差。</p><p><img src="/images/pasted-24.png" alt="upload successful"></p><p><img src="/images/pasted-25.png" alt="upload successful"></p><h2 id="正交性"><a href="#正交性" class="headerlink" title="正交性"></a>正交性</h2><p>如果向量v和w的点积为零，称两向量正交。</p><h2 id="正交集"><a href="#正交集" class="headerlink" title="正交集"></a>正交集</h2><p>如果某一集合中的所有向量相互正交，且均为单位长度，称为规范正交集合。其张成的子空间称为规范正交集。</p><h2 id="扩张空间"><a href="#扩张空间" class="headerlink" title="扩张空间"></a>扩张空间</h2><p>令V为向量空间，元素v1，v2，…..，vn∈V。</p><p>将这些元素与标量相乘加和，所有的线性组合集称为扩张空间。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;机器学习线性代数基础&quot;&gt;&lt;a href=&quot;#机器学习线性代数基础&quot; class=&quot;headerlink&quot; title=&quot;机器学习线性代数基础&quot;&gt;&lt;/a&gt;机器学习线性代数基础&lt;/h1&gt;&lt;p&gt;在机器学习和深度学习中，我们涉及到线性代数的这些知识：&lt;/p&gt;
&lt;ul&gt;
&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>hello</title>
    <link href="https://eurekax.github.io/2020/10/29/hello/"/>
    <id>https://eurekax.github.io/2020/10/29/hello/</id>
    <published>2020-10-29T14:04:31.000Z</published>
    <updated>2020-10-29T14:04:31.178Z</updated>
    
    
    
    
    
  </entry>
  
</feed>
